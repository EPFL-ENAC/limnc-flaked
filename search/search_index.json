{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"EPFL Flaked","text":"<p>EPFL Flaked is service that uploads L\u00e9XPLORE data to EAWAG datalakes repository.</p> <p>See documentation of the client command-line tool at Flake.</p>"},{"location":"api/","title":"API","text":"<p>Flaked is a process that runs in the background. It exposes a REST API so that one can query the current status of the service, and can modify the configuration.</p> <p>The interactive documentation of the REST API is available at http://127.0.0.1:8000/docs.</p>"},{"location":"api/#scheduler-status","title":"Scheduler status","text":"<p>It is possible to start/stop or pause/resume the scheduler.</p>"},{"location":"api/#instrument-jobs","title":"Instrument jobs","text":"<p>For each instrument scheduling directive (<code>cron</code> or <code>interval</code>) there is a job. Each of this job has the following properties:</p> Key Description <code>id</code> The job unique identifier, is based on the corresponding instrument's name, postfixed by the scheduling type. <code>name</code> The name of the corresponding instrument. <code>trigger</code> The trigger directive, either an interval in seconds or the details of the cron expression. <code>next_run_time</code> When will be the next execution. When the job is paused, there is none. <p>It is possible to start/stop or pause/resume a job in the scheduler. Stopping removes the job from the scheduler, restarting it recreates the job according to the instrument specifications. Pausing a job postpones its next execution. Resuming it recalculates the next run time according to the job trigger definition.</p>"},{"location":"api/#logs","title":"Logs","text":"<p>For each instrument it is possible to download the logs. The logs are stored in a rolling file, and by default only the last 100 lines are reported. The log file is rotated when it reaches 1MB. Five log files are kept, the oldest is deleted when a new one is created.</p> <p>The format of the log file is CSV (without an header) with the columns:</p> <ul> <li><code>timestamp</code>: datetime of the log entry</li> <li><code>level</code>: the log level of the log entry</li> <li><code>instrument</code>: the instrument name</li> <li><code>job</code>: the job identifier</li> <li><code>action</code>: the type of action that produced the log entry</li> <li><code>message</code>: the human readable message</li> <li><code>arguments</code>: some informative metrics, optional</li> </ul> <p>The logs API allows to download the last lines of the logs of a specific instrument, or all the logs in a zip file.</p>"},{"location":"config/","title":"Configuration","text":"<p>The configuration describes the system settings and a list of instrument descriptions, which specifies how to process the instrument data files. The format of the configuration file is YAML, and the file is named <code>config.yml</code>.</p> <p>Example of configuration file:</p> <pre><code># Configuration file for Flaked\nsettings:\n  sftp:\n    host: sftp.datalakes.org\n    port: 22\n    prefix: data\n    username: test\n    password: test\n  logs:\n    path: logs\n  input: work/instruments\n  output: work/backup\ninstruments:\n  - name: instrument1\n    schedule:\n      interval:\n        value: 1\n        unit: minutes\n    preprocess:\n      command: \"ls\"\n      args: [\"-la\"]\n    input:\n      path: instrument1/data\n      filter:\n        skip: 1\n    output:\n      path: instrument1\n  - name: instrument2\n    schedule:\n      cron: \"0 0 * * *\" # every day at midnight\n    input:\n      path: instrument2/data\n      filter:\n        regex: \".*\\\\.csv\"\n    output:\n      path: instrument2\n    logs:\n      path: instrument2\n      level: DEBUG\n</code></pre>"},{"location":"config/#settings","title":"Settings","text":"<p>Some general settings.</p> Key Description <code>sftp</code> SFTP server settings <code>logs</code> Logs settings <code>input</code> Input directory settings, optional <code>output</code> Output directory settings, optional <code>attemps</code> The max number of attempts to try when uploading files, optional, default is <code>3</code> <code>wait</code> The number of seconds to wait between two attempts when uploading files, optional, default is <code>5</code>"},{"location":"config/#sftp","title":"SFTP","text":"<p>How to connect to the SFTP server where the data will be uploaded.</p> Key Description <code>host</code> SFTP server hostname <code>port</code> SFTP server port, default is <code>22</code> <code>prefix</code> SFTP server path prefix, e.g. <code>data</code> <code>username</code> SFTP server username <code>password</code> SFTP server password"},{"location":"config/#logs","title":"Logs","text":"<p>Where the logs will be stored, with which level of details.</p> Key Description <code>path</code> Logs directory base path: if not absolute, it will be relative to the current working directory. <code>level</code> Default log level, possible values: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>."},{"location":"config/#input","title":"Input","text":"Key Description <code>path</code> Input directory path prefix, used if the input directory of an instrument is relative."},{"location":"config/#output","title":"Output","text":"Key Description <code>path</code> Output directory path prefix, used if the input directory of an instrument is relative."},{"location":"config/#instruments","title":"Instruments","text":"<p>An array of instrument descriptors, that define which and how data are to be handled, at which frequency. </p>"},{"location":"config/#instrument","title":"Instrument","text":"Key Description <code>name</code> Instrument name, must be unique. <code>schedule</code> When the input data file must be processed. <code>preprocess</code> Preprocessing command to execute before handling input files, optional. <code>postprocess</code> Postprocessing command to execute after handling output files, optional. <code>input</code> Input data files selector. <code>output</code> Output folder where input files will be moved. <code>logs</code> Logs"},{"location":"config/#schedule","title":"Schedule","text":"<p>There are two kinds of scheduling: - <code>cron</code>: complex scheduling expression - <code>interval</code>: regular intervals of unit of time</p> <p>One or the other, or both, can be defined for an instrument. The corresponding scheduler job identifier will be postfixed by <code>:cron</code> or <code>:interval</code>respectively.</p> Key Description <code>cron</code> Cron expression, see online cron expression generator <code>interval.value</code> Interval integer value. <code>interval.unit</code> Interval unit, possible values are: <code>minutes</code>, <code>hours</code>, <code>days</code>, <code>weeks</code>"},{"location":"config/#preprocess","title":"Preprocess","text":"<p>A pre-processing directive consists of executing a command, before the input files are handled, with optional arguments.</p> Key Description <code>command</code> Path to the command to execute. <code>args</code> Array of command arguments, optional"},{"location":"config/#postprocess","title":"Postprocess","text":"<p>A post-processing directive consists of executing a command, after the output files were handled, with optional arguments.</p> Key Description <code>command</code> Path to the command to execute. <code>args</code> Array of command arguments, optional"},{"location":"config/#input_1","title":"Input","text":"<p>Where are located the input data fiels and how to select them.</p> Key Description <code>path</code> Iutput directory path: if not absolute, it will be relative to the main input directory (if defined) or to the current working directory. <code>filter.skip</code> The number of files to skip, counting from the latest ones. <code>filter.regex</code> A regular expression pattern which file name must match, optional."},{"location":"config/#output_1","title":"Output","text":"<p>In which directory are moved the processed input files.</p> Key Description <code>path</code> Output directory path"},{"location":"config/#logs_1","title":"Logs","text":"<p>Where the logs of the instrument's data processing will be stored, with which level of details. Note that the ouput of the pre/post-processing commands are included in this log.</p> Key Description <code>path</code> Logs directory base path: if not absolute, it will be relative to the main logs directory (if defined) or to the current working directory. <code>level</code> Default log level, possible values: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>."},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#from-github","title":"From Github","text":"<p>Windows preliminary:</p> <ul> <li>install python3 with 'Customize installation': 'Install for all users' and 'Add Python to environment variables' checked</li> <li>install git</li> <li>install nssm</li> </ul> <p>Development version:</p> <pre><code>pip install git+https://github.com/EPFL-ENAC/limnc-flaked.git\n</code></pre> <p>Released version:</p> <pre><code>pip install git+https://github.com/EPFL-ENAC/limnc-flaked.git@1.0.0\n</code></pre> <p>On Windows, register the service:</p> <pre><code>nssm install Flaked &lt;path-to-flaked.exe&gt;\n</code></pre>"},{"location":"installation/#usage","title":"Usage","text":"<p>Manual start, see arguments:</p> <pre><code>flaked --help\n</code></pre> <p>Or as a Windows service, use nssm:</p> <pre><code>nssm start Flaked\n</code></pre>"},{"location":"installation/#upgrade","title":"Upgrade","text":"<p>Make sure to stop the Windows service before upgrading and restart it after:</p> <pre><code>nssm stop Flaked\npip install git+https://github.com/EPFL-ENAC/limnc-flaked.git@1.1.0\nnssm start Flaked\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":"<p>Check nssm status:</p> <pre><code>nssm status Flaked\n</code></pre> <p>Edit nssm configuration:</p> <pre><code>nssm edit Flaked\n</code></pre> <p>Verify server API is accessible at http://127.0.0.1:8000/docs.</p>"}]}